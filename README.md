# AI-ASSISTANT
Ai assistant 


Here's a detailed `README.md` for your GitHub repository based on the provided code and features:

---

# ğŸ§  JARVIS AI Assistant (English)

**A smart desktop assistant powered by Ollama's `phi3:mini` and `llava`, featuring voice interaction, GUI, image input (LLaVA), email, daily tasks, and home control.**

---

## ğŸŒŸ Features

* ğŸ” Continuous speech loop with **interrupt support**
* ğŸ—£ï¸ Speak and respond in **English (default)** or **Tamil** with voice model switching
* ğŸ–¼ï¸ **Image input** via LLaVA for image captioning
* ğŸ›ï¸ Clean **GUI** with command buttons
* ğŸ—“ï¸ Date, time, jokes, music, weather stub
* ğŸ”Œ Control for apps (Notepad, Calculator, Chrome)
* âœ‰ï¸ Email support (SMTP)
* ğŸ§  LLM-powered conversation with local models via Ollama
* ğŸ’¾ SQLite-based **conversation logging**
* ğŸ–±ï¸ File selector for image description
* ğŸ§ª Extensible with Home Automation or Calendar integrations

---

## ğŸ›  Requirements

* Python 3.10+
* Dependencies:

  ```
  pip install -r requirements.txt
  ```
* [Ollama](https://ollama.com) installed and running:

  ```bash
  ollama run phi3:mini
  ollama run llava:13b
  ```

---

## ğŸ’¡ How to Use

1. **Run the script**:

   ```bash
   python jarvis_phi3_template.py
   ```

2. **Speak your commands**. Examples:

   * `"What is the time?"`
   * `"Open Notepad"`
   * `"Play music"`
   * `"Switch to Tamil"`
   * `"Describe this image"` (use GUI)
   * `"Send Email"`
   * `"Exit"` â€“ quits the app

3. Use **GUI buttons** to control JARVIS manually.

---

## ğŸ› GUI Command List

| Button            | Action                              |
| ----------------- | ----------------------------------- |
| Time / Date       | Speak current time/date             |
| Joke              | Tells a light joke                  |
| Music             | Play music via YouTube              |
| Weather           | Stub for weather (customize)        |
| Describe Image    | Image analysis via LLaVA            |
| Stop Speaking     | Interrupt voice output              |
| Export Logs       | Save log to `jarvis_export_log.txt` |
| Email             | Sends email (edit credentials)      |
| Open/Close Apps   | Notepad, Calculator, Chrome         |

---

## ğŸ“‚ Logs

All conversations are saved in `jarvis_logs.db`.

Use the **Export Logs** button to export as text to `jarvis_export_log.txt`.

---

## ğŸ§  Model Switching

* **Default**: English via `phi3:mini`
* Use `"Switch to Tamil"` button to:

  * Change model to `llama3.2-tamil`
  * Change voice to Tamil (if available)
* Revert with `"Switch to English"`

---

## ğŸ“§ Email Setup

Edit your credentials in the `send_email()` function:

```python
server.login("your_email@gmail.com", "your_password")
server.sendmail("your_email@gmail.com", "recipient@example.com", "Message body")
```

Enable **Less secure apps** or use **App Passwords** if using Gmail.

---

## ğŸ› ï¸ Coming Soon / TODO Ideas

* ğŸ”Œ Home automation via MQTT or local API
* ğŸ“… Calendar (Google Calendar or Outlook API)
* ğŸ§  Memory or file-based context
* ğŸŒ Web search integration
* ğŸ™ Wake word ("Hey Jarvis")

---

## ğŸ‘¨â€ğŸ’» Contributing

Pull requests welcome! Make sure your features align with voice interaction and local-first approach. Open an issue for discussion first.

---

## âš ï¸ Disclaimer

This project is experimental and runs local LLMs. Always test responsibly. Ensure secure handling of email credentials.

---

## ğŸ“¸ Screenshot

> *(Add a screenshot of the GUI running)*

---

## ğŸ“„ License

MIT License

---

Let me know if you want a PDF/markdown copy or if you'd like it tailored for deployment (e.g., `.exe` with PyInstaller, etc.).

---

# ğŸ¤– JARVIS AI Assistant (with Ollama + Mistral Integration)

![JARVIS Logo](JARVIS_LOGO.PNG) <sub><sup>*Smart Voice AI Assistant powered by Ollama and OpenAI*</sup></sub>

---

## ğŸ¬ Demo

![JARVIS Demo](jarvis_demo.gif) <sub><sup>*JARVIS GUI, voice, and image interaction in action*</sup></sub>

---

## ğŸ§  Features

* ğŸ™ï¸ Voice-controlled assistant using `speech_recognition`
* ğŸ—£ï¸ Natural speech replies with `pyttsx3`
* ğŸ–¼ï¸ Image analysis via `llava:13b` (multimodal LLM)
* ğŸ” Switch models: `mistral`, `llama3`, `llava`
* ğŸŒ GPT-4 (via OpenAI) fallback chat
* ğŸ§¾ Notes, reminders, search, calculator, and more
* ğŸ§  Memory saving to JSON
* ğŸ’» GUI powered by `tkinter`
* ğŸ”Š Thread-safe, interruptible TTS
* ğŸ¤ Voice & text input both supported

---

## ğŸš€ Getting Started

### âœ… Prerequisites

* Python 3.9+
* [Ollama](https://ollama.com/) installed
* Models: `mistral`, `llava`, `llama3:8b`
* OpenAI API Key (for GPT-4 fallback)

### ğŸ“¦ Install Dependencies

```bash
pip install pyttsx3 SpeechRecognition requests openai pillow
```

> ğŸ›  For Windows:
>
> ```bash
> pip install pipwin
> pipwin install pyaudio
> ```

---

## âš™ï¸ Configuration

### ğŸ”‘ OpenAI Key

Edit in the `.py` file:

```python
openai.api_key = "your-openai-key"
```

### ğŸ§  Ollama Model Setup

Run the models you want:

```bash
ollama run mistral
ollama run llava
ollama run llama3:8b
```

---

## ğŸ–¥ï¸ Run It

```bash
python jarvis_running_on_ollama_misteral_model.py
```

---

## ğŸ—£ï¸ Voice Commands

Examples:

* â€œWhatâ€™s the time?â€
* â€œOpen calculatorâ€
* â€œSwitch model to llavaâ€
* â€œTake a noteâ€
* â€œStart AI conversationâ€
* â€œDescribe imageâ€
* â€œAsk online AIâ€
* â€œExit JARVISâ€

---

## ğŸ“· Image Support

* Select `.jpg`, `.jpeg`, `.png`
* Ask questions about the image
* Uses `llava` for vision + language

---

## ğŸ“‚ Structure

```
ğŸ“ assets/
  â””â”€ jarvis_logo.png
  â””â”€ jarvis_demo.gif
ğŸ“ jarvis_running_on_ollama_misteral_model.py
ğŸ§  conversation_memory.json
ğŸ““ notes.txt
```

---

## ğŸ“Œ Known Issues

* Ollama server must be running
* Online features need internet
* No multilingual support (yet)

---

## ğŸ“„ License

MIT License

---

## ğŸ™Œ Credits

Built by **NARENDHRA PRASHATH VS**
Powered by **Python**, **Ollama**, **OpenAI**, **Tkinter*
